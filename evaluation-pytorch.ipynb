{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, datasets\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import PIL\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "#    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "NUM_WROKERS = 8\n",
    "INPUT_IMG_SIZE = (101, 101)\n",
    "EPOCH = 200                # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.0001               # learning rate\n",
    "#MODELS_ROOT = './models'\n",
    "CLASSES = np.loadtxt('./dataset/class_id.txt', str, delimiter='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loading methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation method \n",
    "Create own dataset loader wtih following code strcture\n",
    "\n",
    "```python\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        ##############################################\n",
    "        ### Initialize paths, transforms, and so on\n",
    "        ##############################################\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ##############################################\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        ##############################################\n",
    "        \n",
    "    def __len__(self):\n",
    "        ##############################################\n",
    "        ### Indicate the total size of the dataset\n",
    "        ##############################################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, classes):\n",
    "    img_paths = []\n",
    "    labels = []\n",
    "    for class_id, class_name in enumerate(classes):\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        for filename in os.listdir(class_folder):\n",
    "            filename.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "            img_paths.append(os.path.join(class_folder, filename))\n",
    "            labels.append(class_id)\n",
    "    return img_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_img(batch_data):   \n",
    "    # show images\n",
    "    imgs = torchvision.utils.make_grid(batch_data)\n",
    "    imgs = imgs / 2 + 0.5     # unnormalize\n",
    "    npimgs = imgs.numpy()\n",
    "    plt.rcParams['figure.figsize'] = [12, 5]\n",
    "    plt.imshow(np.transpose(npimgs, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset random loading test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrailnetDataset(Dataset):\n",
    "    def __init__(self, datalist_filename):\n",
    "        classes = CLASSES\n",
    "        \n",
    "        self.img_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        txt = np.loadtxt(datalist_filename, str, delimiter='\\n')\n",
    "        for line in txt:\n",
    "            p, l  = line.split()\n",
    "            self.img_list.append(p)\n",
    "            self.label_list.append(l)\n",
    "        \n",
    "        print( '********** Dataset Info start **********\\n')\n",
    "        print('Source: ', datalist_filename) \n",
    "        print('Output classes: ', classes) \n",
    "        print( 'Amount of images: ', len(txt))\n",
    "        print('\\n*********** Dataset Info end ***********\\n') \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        self.data_transform = transforms.Compose([ \n",
    "                                transforms.Resize(INPUT_IMG_SIZE), \\\n",
    "                                transforms.ToTensor(), \\\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], \\\n",
    "                                                     std=[1, 1, 1]), \\\n",
    "                                ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def collect_folders_from_dataset(self, dataset_root, classes):\n",
    "        # Implement by BFS\n",
    "        search_list = [dataset_root, ]\n",
    "        dataset_folders = [] \n",
    "        while len(search_list) != 0:\n",
    "            root = search_list.pop(0)\n",
    "            if set(os.listdir(root)) == set(classes):\n",
    "                dataset_folders.append(root)\n",
    "            else:\n",
    "                for folder in os.listdir(root):\n",
    "                    path = os.path.join(root, folder)\n",
    "                    if os.path.isdir(path):\n",
    "                        search_list.append(path)\n",
    "        return dataset_folders\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # print self.img_list[index]\n",
    "        # Select sample, then load data and get label\n",
    "        path = self.img_list[index]\n",
    "        img_raw = self.default_loader(path)\n",
    "        x = self.data_transform(img_raw)\n",
    "        z = float(self.label_list[index])\n",
    "        y = int((z/8.5+1)*7)\n",
    "  \n",
    "        return x, y, path\n",
    "    \n",
    "    def pil_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            with PIL.Image.open(f) as img:\n",
    "                return img.convert('RGB')\n",
    "\n",
    "    def accimage_loader(self, path):\n",
    "        try:\n",
    "            return accimage.Image(path)\n",
    "        except IOError:\n",
    "            # Potentially a decoding problem, fall back to PIL.Image\n",
    "            return pil_loader(path)\n",
    "\n",
    "    def default_loader(self, path):\n",
    "        if torchvision.get_image_backend() == 'accimage':\n",
    "            return self.accimage_loader(path)\n",
    "        else:\n",
    "            return self.pil_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "val_dataset = TrailnetDataset(datalist_filename='./dataset/test.txt')\n",
    "img , l, _path = random.choice(val_dataset)\n",
    "print( type(img),type(l))\n",
    "\n",
    "print('Image size: ', img.size()) \n",
    "print('Ground true: ', l) \n",
    "print('Image: ') \n",
    "vis_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model declare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 15),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class TrailNet15Class(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TrailNet3Class, self).__init__()\n",
    "#         # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "#         # kernel\n",
    "#         self.conv1 = nn.Conv2d(3, 32, 4)\n",
    "#         self.pool1 = nn.MaxPool2d((2, 2), stride=2)\n",
    "#         self.conv2 = nn.Conv2d(32, 32, 4)\n",
    "#         self.pool2 = nn.MaxPool2d((2, 2), stride=2)\n",
    "#         self.conv3 = nn.Conv2d(32, 32, 4)\n",
    "#         self.pool3 = nn.MaxPool2d((2, 2), stride=2)\n",
    "#         self.conv4 = nn.Conv2d(32, 32, 4, padding=(2, 2))\n",
    "#         self.pool4 = nn.MaxPool2d((2, 2), stride=2)\n",
    "#         # an affine operation: y = Wx + b\n",
    "#         self.fc1 = nn.Linear(800, 200)\n",
    "#         self.fc2 = nn.Linear(200, 15)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool1(self.conv1(x))\n",
    "#         x = self.pool2(self.conv2(x))\n",
    "#         x = self.pool3(self.conv3(x)) \n",
    "#         x = self.pool4(self.conv4(x))    \n",
    "#         # print 'x size: ', x.size()   \n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "#         # print 'x size: ', x.size()   \n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "#     def num_flat_features(self, x):\n",
    "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "#         num_features = 1\n",
    "#         for s in size:\n",
    "#             num_features *= s\n",
    "#         return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(model, filename, use_cuda=True):\n",
    "    if filename.lower().endswith('.pth'):\n",
    "        state_dict = torch.load(os.path.join(filename))\n",
    " \n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        cudnn.benchmark = True\n",
    "        model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TrailNet3Class()\n",
    "model = AlexNet()\n",
    "\n",
    "\n",
    "load_pretrained_model(model, '/home/alex/imitation_learning/AlexNet_pytorch/models/7.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to pack our custom dataset\n",
    "\n",
    "There are two type dataset inputs of torch.utils.data.DataLoader, **one is map-style** which implemented by \n",
    "inheriting [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset), **the other one is iterable-style** implemented by inheriting [IterableDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TrailnetDataset(datalist_filename='./dataset/test.txt')\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WROKERS, shuffle=False) \n",
    "\n",
    "cnt = 0\n",
    "for idx, (images, targets, _path) in enumerate(test_loader):\n",
    "    images, targets = images.cuda(), targets.cuda()\n",
    "    \n",
    "    output = model(images)\n",
    "    pred = output.argmax(axis=1)\n",
    "#    print( 'ground true: ', pred)\n",
    "#    print('pretiction : ', targets) \n",
    "    for i in range(len(targets)):\n",
    "        if pred[i] == targets[i]:\n",
    "            cnt = cnt + 1\n",
    "print( 'Accuracy: {:.2f} %'.format(float(cnt)/261 * 100)) #img number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
